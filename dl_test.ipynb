{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobz653/AD3/blob/master/dl_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB8JOKTSt-Sv",
        "colab_type": "code",
        "outputId": "567d76bc-9a56-4536-ae1b-ca12b0dd1d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = 3\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdq0PVvIuk7I",
        "colab_type": "code",
        "outputId": "557840b1-8ebe-464c-d048-d004debe0f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2200 - acc: 0.9347\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0989 - acc: 0.9698\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0705 - acc: 0.9774\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0541 - acc: 0.9830\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0428 - acc: 0.9860\n",
            "10000/10000 [==============================] - 1s 51us/sample - loss: 0.0644 - acc: 0.9816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06437434618612752, 0.9816]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6qXx-ctaI5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDic1uzzR8bk",
        "colab_type": "code",
        "outputId": "79a93574-34d5-4826-e640-815700a7353f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#!wget https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Titanic.csv -P drive/app\n",
        "  \n",
        "import pandas as pd\n",
        "titanic = pd.read_csv(\"drive/app/Titanic.csv\")\n",
        "titanic.head(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Class</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1st</td>\n",
              "      <td>Male</td>\n",
              "      <td>Child</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2nd</td>\n",
              "      <td>Male</td>\n",
              "      <td>Child</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3rd</td>\n",
              "      <td>Male</td>\n",
              "      <td>Child</td>\n",
              "      <td>No</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Crew</td>\n",
              "      <td>Male</td>\n",
              "      <td>Child</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1st</td>\n",
              "      <td>Female</td>\n",
              "      <td>Child</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Class     Sex    Age Survived  Freq\n",
              "0           1   1st    Male  Child       No     0\n",
              "1           2   2nd    Male  Child       No     0\n",
              "2           3   3rd    Male  Child       No    35\n",
              "3           4  Crew    Male  Child       No     0\n",
              "4           5   1st  Female  Child       No     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSE45UWHawMA",
        "colab_type": "code",
        "outputId": "28b8c3aa-14df-4d33-ca4b-a91dd249b09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/b5/63b79fe426433fa1cd110eb04a94ec0c6967e56e5f57c98caf455a5fb6e2/numpy-1.16.1-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0MB 2.6MB/s \n",
            "\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sLYrBVcaKzT",
        "colab_type": "code",
        "outputId": "6aac4111-f501-4ee3-fc2e-2d2fd4af0387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "class Position_Embedding(Layer):\n",
        "    \n",
        "    def __init__(self, size=None, mode='sum', **kwargs):\n",
        "        self.size = size #必须为偶数\n",
        "        self.mode = mode\n",
        "        super(Position_Embedding, self).__init__(**kwargs)\n",
        "        \n",
        "    def call(self, x):\n",
        "        if (self.size == None) or (self.mode == 'sum'):\n",
        "            self.size = int(x.shape[-1])\n",
        "        batch_size,seq_len = K.shape(x)[0],K.shape(x)[1]\n",
        "        position_j = 1. / K.pow(10000., \\\n",
        "                                 2 * K.arange(self.size / 2, dtype='float32' \\\n",
        "                               ) / self.size)\n",
        "        position_j = K.expand_dims(position_j, 0)\n",
        "        position_i = K.cumsum(K.ones_like(x[:,:,0]), 1)-1 #K.arange不支持变长，只好用这种方法生成\n",
        "        position_i = K.expand_dims(position_i, 2)\n",
        "        position_ij = K.dot(position_i, position_j)\n",
        "        position_ij = K.concatenate([K.cos(position_ij), K.sin(position_ij)], 2)\n",
        "        if self.mode == 'sum':\n",
        "            return position_ij + x\n",
        "        elif self.mode == 'concat':\n",
        "            return K.concatenate([position_ij, x], 2)\n",
        "        \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.mode == 'sum':\n",
        "            return input_shape\n",
        "        elif self.mode == 'concat':\n",
        "            return (input_shape[0], input_shape[1], input_shape[2]+self.size)\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "\n",
        "    def __init__(self, nb_head, size_per_head, mask_right=False, **kwargs):\n",
        "        self.nb_head = nb_head\n",
        "        self.size_per_head = size_per_head\n",
        "        self.output_dim = nb_head*size_per_head\n",
        "        self.mask_right = mask_right\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.WQ = self.add_weight(name='WQ', \n",
        "                                  shape=(input_shape[0][-1], self.output_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True)\n",
        "        self.WK = self.add_weight(name='WK', \n",
        "                                  shape=(input_shape[1][-1], self.output_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True)\n",
        "        self.WV = self.add_weight(name='WV', \n",
        "                                  shape=(input_shape[2][-1], self.output_dim),\n",
        "                                  initializer='glorot_uniform',\n",
        "                                  trainable=True)\n",
        "        super(Attention, self).build(input_shape)\n",
        "        \n",
        "    def Mask(self, inputs, seq_len, mode='mul'):\n",
        "        if seq_len == None:\n",
        "            return inputs\n",
        "        else:\n",
        "            mask = K.one_hot(seq_len[:,0], K.shape(inputs)[1])\n",
        "            mask = 1 - K.cumsum(mask, 1)\n",
        "            for _ in range(len(inputs.shape)-2):\n",
        "                mask = K.expand_dims(mask, 2)\n",
        "            if mode == 'mul':\n",
        "                return inputs * mask\n",
        "            if mode == 'add':\n",
        "                return inputs - (1 - mask) * 1e12\n",
        "                \n",
        "    def call(self, x):\n",
        "        #如果只传入Q_seq,K_seq,V_seq，那么就不做Mask\n",
        "        #如果同时传入Q_seq,K_seq,V_seq,Q_len,V_len，那么对多余部分做Mask\n",
        "        if len(x) == 3:\n",
        "            Q_seq,K_seq,V_seq = x\n",
        "            Q_len,V_len = None,None\n",
        "        elif len(x) == 5:\n",
        "            Q_seq,K_seq,V_seq,Q_len,V_len = x\n",
        "        #对Q、K、V做线性变换\n",
        "        Q_seq = K.dot(Q_seq, self.WQ)\n",
        "        Q_seq = K.reshape(Q_seq, (-1, K.shape(Q_seq)[1], self.nb_head, self.size_per_head))\n",
        "        Q_seq = K.permute_dimensions(Q_seq, (0,2,1,3))\n",
        "        K_seq = K.dot(K_seq, self.WK)\n",
        "        K_seq = K.reshape(K_seq, (-1, K.shape(K_seq)[1], self.nb_head, self.size_per_head))\n",
        "        K_seq = K.permute_dimensions(K_seq, (0,2,1,3))\n",
        "        V_seq = K.dot(V_seq, self.WV)\n",
        "        V_seq = K.reshape(V_seq, (-1, K.shape(V_seq)[1], self.nb_head, self.size_per_head))\n",
        "        V_seq = K.permute_dimensions(V_seq, (0,2,1,3))\n",
        "        #计算内积，然后mask，然后softmax\n",
        "        A = K.batch_dot(Q_seq, K_seq, axes=[3,3]) / self.size_per_head**0.5\n",
        "        A = K.permute_dimensions(A, (0,3,2,1))\n",
        "        A = self.Mask(A, V_len, 'add')\n",
        "        A = K.permute_dimensions(A, (0,3,2,1)) \n",
        "        if self.mask_right:\n",
        "            ones = K.ones_like(A[:1, :1])\n",
        "            mask = (ones - K.tf.matrix_band_part(ones, -1, 0)) * 1e12\n",
        "            A = A - mask\n",
        "        A = K.softmax(A)\n",
        "        #输出并mask\n",
        "        O_seq = K.batch_dot(A, V_seq, axes=[3,2])\n",
        "        O_seq = K.permute_dimensions(O_seq, (0,2,1,3))\n",
        "        O_seq = K.reshape(O_seq, (-1, K.shape(O_seq)[1], self.output_dim))\n",
        "        O_seq = self.Mask(O_seq, Q_len, 'mul')\n",
        "        return O_seq\n",
        "        \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0][0], input_shape[0][1], self.output_dim)\n",
        "      \n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "\n",
        "S_inputs = Input(shape=(None,), dtype='int32')\n",
        "embeddings = Embedding(max_features, 128)(S_inputs)\n",
        "# embeddings = Position_Embedding()(embeddings) # 增加Position_Embedding能轻微提高准确率\n",
        "O_seq = Attention(8,16)([embeddings,embeddings,embeddings])\n",
        "O_seq = GlobalAveragePooling1D()(O_seq)\n",
        "O_seq = Dropout(0.5)(O_seq)\n",
        "outputs = Dense(1, activation='sigmoid')(O_seq)\n",
        "\n",
        "model = Model(inputs=S_inputs, outputs=outputs)\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0625 07:02:45.731015 140447408678784 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0625 07:02:45.746001 140447408678784 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0625 07:02:45.777964 140447408678784 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0625 07:02:45.805052 140447408678784 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0625 07:02:45.815071 140447408678784 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Train...\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 14s 560us/step - loss: 0.4134 - acc: 0.8083 - val_loss: 0.3528 - val_acc: 0.8435\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 10s 397us/step - loss: 0.2535 - acc: 0.8952 - val_loss: 0.3922 - val_acc: 0.8284\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 10s 398us/step - loss: 0.1776 - acc: 0.9313 - val_loss: 0.4732 - val_acc: 0.8136\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 10s 398us/step - loss: 0.1223 - acc: 0.9546 - val_loss: 0.6439 - val_acc: 0.8005\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 10s 396us/step - loss: 0.0831 - acc: 0.9689 - val_loss: 0.8542 - val_acc: 0.7918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc2997c790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}